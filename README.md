# speech
В общем просил один товарищ рассказать, как я использовал службу Yandex speechkit чтобы распознавать речь в видеофайлах. Начнём с того что рассмотрим процесс в общем. Для того чтобы получить доступ к инструментам Яндекса нужно пройти девять кругов ада. И что Самое печальное - нигде нет полной инструкции как это сделать. Всё приходится собирать опять как всегда по крупицам. Я это прошёл 1 раз и сейчас примерно вспомню как я это делал. Для начала необходимо завести аккаунт на Яндекс Облаке. Привязать свою карточку, номер телефона, верифицироваться и закинуть денег. Это всё необходимо потому что все эти сервисы Яндекса не бесплатные. Есть какой-то пробный период.  Дают какие-то пробные пару тысяч, но, как правило, они быстро заканчиваются. И всё равно придётся тратить свои кровные. 
В принципе, как зайти на самой Яндекс облако, как создать аккаунт и как зайти в консоль это всё вы сможете самостоятельно найти на ресурсах яндексах. Для таких простых вещей там есть инструкция. Я думаю, что получится у каждого. 
После того как мы создали своё облако для того чтобы воспользоваться распознаванием речи нам нужно создать свой object storage, а внутри него создать bucket. Грубо говоря мы покупаем у Яндекса место для хранения файлов и создаём диск. Я вот арендовал себе немного места и создал ведёрко. Дал этому ведёрку название. Зачем я это сделал Я объясню чуть позже. 
Теперь мы хотим распознавать речь программным путём. В том смысле что мы будем обращаться к сервисам Яндекса программно, то есть через программный код. Например, я написал программку в питоне. Через эту программу я автоматически закидываю файлы на сервер и делаю запросы на их распознавание. На сервере файлы распознаются, а мне передаются ответы. Насколько я разобрался для этого нужно завести сервисный аккаунт в Яндекс облаке, это отдельная вещь внутри вашего аккаунта. Сервисный аккаунт можно завести через консоль вот здесь. Здесь можно создать сервисный аккаунт. Вот я создал один и назначил ему различные роли. Вот эта запись storage Editor означает что у этого сервисного аккаунта есть доступ к моему бакету, то есть к моему хранилищу.  Соответственно он имеет доступ ко всем файлам, которые там находятся. Также по инструкциям в сервисном аккаунте необходимо создать разные ключи. Эти ключи дают вашим программам, то есть вашему программному коду, доступ как к хранилищу, так и к функциям типа Yandex speechkit. Естественно к другим инструментам тоже нужен этот ключ. Далее я покажу где они используются в программном коде. 
Таким образом в сервисном аккаунте мы должны создать API ключ и ключ доступа. 
Также в ACL бакета надо добавить наш сервисный аккаунт в разрешение на чтение и запись. Я показывал чуть выше где можно посмотреть разрешения на доступ к ведру. Сейчас покажу где этот ACL находится. Вот собственно здесь можно задавать эти роли. Ну то есть разрешения. 
После того как мы настроили свой аккаунт мы уже можем переходить к программному коду в питоне. У меня стоит пакет анаконда, но дополнительно Мне нужно было скачать библиотеки boto3 и moviepy. Библиотека boto3 нужно для того чтобы мы могли обращаться к облаку Яндекса. А Библиотека moviepy Мне была необходима для работы с видеофайлами. У меня было много видео файлов. И мне нужно было пройтись по всем файлам и проверить наличие нежелательных слов в этих файлах. Естественно сидеть и слушать десятки часов собственной болтовни очень скверная перспектива. Я решил прогнать все эти видео через распознавание речи и дальше уже в текстовом виде анализировать содержание. Конечно мне ещё нужны были моменты времени, когда слова произносятся, то есть нужна была полноценная стенограмма с тайм-кодами. Для этого мне нужно было из видео файлов снять аудио дорожку и уже её передать в сервис Яндекс. Если у вас сразу audiofile то тут тоже есть один нюанс. Сервис Яндекс speechkit распознаёт файлы только в формате ogg. С форматом, например, MP3 Yandex speechkit не работает. Давайте посмотрим где вообще располагается этот speechkit и где про него можно что-то почитать. Есть 3 разных режима распознавание речи: распознавание коротких видео, потоковый режим и распознавание длинных аудио. Вот третий нам и нужен.  Распознавание коротких аудио подходит для файлов длительностью всего лишь несколько секунд. На данной странице можно увидеть некоторые рекомендации или некоторые инструкции как воспользоваться этим сервисом, но всё-таки четкой инструкцией это назвать сложно. Вот так сразу и без бутылки разобраться не получится. Вот как раз есть пример на питоне, который я доработал под себя и использовал. 
Итак, после установки дополнительных библиотек можно приступать к работе. В общем виде процесс выглядит так: сначала с видео снимаю звук в формате mp3, затем через стороннюю программу ffmpeg конвертирую MP3 в формат ogg. Делаю это через вызов командной строки прямо из питона. Через сессию boto3 загружаю полученные аудиофайлы в нужном формате к себе в баке и затем формирую запрос, в котором прошу систему распознать аудио файл в моём бакете. Через какое-то время получаю ответ в формате json и радуюсь результату. 
Теперь посмотрим на сам программный код и сразу видно, что я не программист и весь код написан через жопу. Но он работает и это главное!
Сначала импортирую библиотеки. Затем указывают имя файла, который необходимо обработать.  
После того как я получил аудиодорожки в нужном формате я должен загрузить их в ведёрко. Чтобы вам сделать тоже самое вам необходимо указать две переменные: ключ доступа и секретный ключ который к нему идёт в комплекте. Эти ключи Вы должны получить в тот момент, когда будете создавать сервисный аккаунт. Секретный ключ нигде не сохраняется поэтому Вам самим надо будет его скопировать в текстовый файл и сохранить у себя на компьютере. Затем Вы укажите его в программном коде. При загрузке вам будет необходимо указать имя ведра таким какое вы ему заданили в Облаке. Список файлов в вашем ведерке можно получить таким вот образом. 
Теперь мы добрались до самой стадии распознавания. Здесь вам также надо будет подставить свой API ключ и указать путь к фалу в вашем бакете. Указанная модель распознавания относится к общему русскому языку, но она является самой дешёвой. Это модель, которая стоит не первая в очереди на распознавание. То есть вам придется немного дольше ждать. Зато цена на порядок ниже. 
Дальше формируется запрос на распознавание. После отправки запроса результат проверяется в цикле while и исполняется до получения ответа. Ответ получен в формате json. С этим форматом можно также ознакомиться в интернете. Конкретный формат ответа Яндекс speechkit также приведён на странице Yandex Cloud. Как видите каждую строчку он выдаёт дважды. Звук у меня двухканальный поэтому он распознал каждый канал отдельно. Также показан ответ в формате json, здесь указаны конкретные фразы, слова и время, когда они произнесены.  
С помощью цикла можно обработать этот ответ и сохранить в текстовом виде в любом для себя удобном формате. Я также использовал этот инструмент для определения интервалов молчания в видео, а потом использовал эти интервалы для того чтобы вырезать эти моменты. Таким образом видео процентов на 20-30 становится короче. Без этих пауз видео более удобно для восприятия на слух и не занимает лишнего времени. Например, в моих видео, которые длятся около 2 часов минут 20 или 30 занимают эти ненужные паузы. Но потом я сделал для себя другой инструмент, который более эффективным. Как-нибудь в другой раз я про него расскажу. А этот так и остался для распознавания речи и анализа в тексте. После распознавания всех видео и поиска в тексте ненужных слов дальше в видеоредакторе я просто в эти моменты поставил заглушку. 
Кстати, весь этот текст я написал в Word, а потом синтезировал речь через Yandex speechkit.
